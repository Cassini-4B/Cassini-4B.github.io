---
layout: post
#h2
title: NSF Funding, Soup and Goats <br><br> ## The Secret Formula

---

For my 2nd project, I decided to see if there existed some secret formula, that when configured
just right, could predict the amount of grant funding you would be awarded by the NSF.  I thought
this might be a worthwhile project because: <br><br>
	a) Grant proposals are the stuff of nightmares, and are therefore in need of some sort of
	  magical cure, and <br><br>
	b) I like the idea of taking a complicated, life draining process and throwing it into a
	linear regressor to come up with a nice linear equation that can transform the whole 	
	process	into a seemingly harmless little collection of coefficients and vectors.  
	![alt_text](/pics/Perfect-Grant-Writing-Formula-Cartoon-1024x773.jpg)


To start this project, I had to reach for some soup.  Specifically the beautiful kind, as in BeautifulSoup in python to scrape the NSF website for award summary data: <br><br>
[National Science Foundation Awards Summary](https://dellweb.bfa.nsf.gov/AwdLst2/default.asp) <br><br>
But unfortunately I ran into some issues right away, as the NSF award statistics webpage was configured such that the html code populated their award summary data table only when the user selected a specific State or Institution, which was then sent to their servers as query response data and which generated asp requests to get the corresponding award summary information.  Neither BeautifulSoup nor Selenium (the other web scraping option available in python) were able to automatically generate these requests and responses alone (I would have to incorporate scrapy as well).

So instead, I used BeautifulSoup to scrape their download data page to retrieve xml files containing award statistics from 2013-2018.  That gave me around 60,000 awards to look at over the 5 year period.

I then started exploring.  Could any of the information contained in these files provide the secret formula for grant funding?  Well, first I needed to see what I had to work with.  I had data on award effective dates and end dates, award amended dates, state, university/institution name, fields (Social sciences, computer science, engineering, etc) and abstracts.  I did some simple pandas calculations to quantify these features: grant lengths, amended lengths, word count of abstracts, and I also pulled in university rankings (by amount of R&D expenditure and total number of graduate students) as well as historical data (number of grant proposals submitted vs number of grants approved).  

### Time to cook!  

I tried a simple linear regression at first.  I split the data (70/30) into a training and testing set and fit the training data to the linear regression model in python.  I then generated predicted award amount values for the features in the testing set.  My model did not predict very well at all, as shown in this plot of predicted vs actual values: ![alt_text](/pics/Modelperf.jpg) 

As my model was fitting so poorly and my RSME values were so high, I decided to do some model diagnostics.  First, I plotted a correlation heatmap and looked at the distribution of the data to get a better sense of how the data varied with abstract funding:
![alt_text](/pics/Modelperf.jpg) 

Then I calculated the variance inflation factor to see if any of the independent features in my dataset should be removed: ![alt_text](/pics/vif.png) While the VIF for Grant Length was not extremely high, it was still over 5, so I re-ran my linear regression model without this feature in the dataset, but it did not make an appreciable difference to the results.

I then looked at the variance of the error in my model by plotting the predicted award amounts against the residuals of the model: ![alt_text](/pics/residuals.png)  In this plot you can clearly see that the distribution of residuals is not random, so the error variance is not constant.

So I decided to try a transformation where I took the natural log of the award amount data and used that instead to fit to my linear regressor.  In this case, I would be trying to see if any of the features listed above had any significant effect on the percentage of change of award amount data.  Here are my results of my model below:

 
 
It's a Python library (for both Python 2 and 3) that is easy to install and implement.  The documentation page has great tutorials that get you set up and running pretty quSiickly:
[Installation](https://textblob.readthedocs.io/en/dev/install.html)

Since it's a been pretty easy to get set up, I was able to run with some simple text processing:
as s
   * Noun-phrase extractionli
   * POS Tagging
   * Sentiment Analysis
   * Language Translation
   * Text Summary



This was my first real hands-on (from scratch) NLP task, so it was fun to go through and see all these steps in motion. If you'd like to walk through my adventure in TextBlob, here's my jupyter notebook:

[TextBlob Notebook](https://github.com/Cassini-4B/Cassini-4B.github.io/blob/master/_download/textblob.ipynb)

 
Thanks!
